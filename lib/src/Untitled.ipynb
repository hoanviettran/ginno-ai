{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lfw_batch_size LFW_BATCH_SIZE]\n",
      "                             [--image_size IMAGE_SIZE]\n",
      "                             [--detect_multiple_faces DETECT_MULTIPLE_FACES]\n",
      "                             [--margin MARGIN] [--random_order]\n",
      "                             [--gpu_memory_fraction GPU_MEMORY_FRACTION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-67353fe4-a67d-4453-86ce-8e4650640015.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/light/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import lfw\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import sys\n",
    "from scipy import misc\n",
    "import math\n",
    "import tqdm\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "from align import detect_face\n",
    "import retrieve\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 160\n",
    "lfw_batch_size = 100\n",
    "model = '/mnt/data/Face_Recognition-vinayak/lib/src/ckpt/20180408-102900/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/data/Face_Recognition-vinayak/lib/src/ckpt/20180408-102900/model-20180408-102900.ckpt-90\n"
     ]
    }
   ],
   "source": [
    "model_exp = '/mnt/data/Face_Recognition-vinayak/lib/src/ckpt/20180408-102900/'\n",
    "graph_fr = tf.Graph()\n",
    "sess_fr = tf.Session(graph=graph_fr)\n",
    "\n",
    "with graph_fr.as_default():\n",
    "    saverf = tf.train.import_meta_graph(os.path.join(model_exp, 'model-20180408-102900.meta'))\n",
    "    saverf.restore(sess_fr, os.path.join(model_exp, 'model-20180408-102900.ckpt-90'))\n",
    "    pnet, rnet, onet = detect_face.create_mtcnn(sess_fr, None)\n",
    "\n",
    "\n",
    "# with tf.Graph().as_default():\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         # Load the model\n",
    "#         facenet.load_model(model)\n",
    "#         images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "#         images_placeholder = tf.image.resize_images(images_placeholder,(160,160))\n",
    "#         embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "#         phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "#         embedding_size = embeddings.get_shape()[1]\n",
    "#         src_path = '/home/hoanviettran/Downloads/train/Aaron_Peirsol'\n",
    "#         files = [f for f in listdir(src_path) if isfile(join(src_path, f))]\n",
    "#         images = np.zeros((len(files), image_size, image_size, 3))\n",
    "#         for j, file_name in enumerate(files):\n",
    "#             file_path = src_path + '/' + file_name\n",
    "#             img = misc.imread(file_path)\n",
    "#         #     response, faces, bboxs = align_face(img, pnet, rnet, onet)\n",
    "#             images[j,:,:,:] = facenet.load_img(img, image_size)\n",
    "#         feed_dict = {images_placeholder:images, phase_train_placeholder:False}\n",
    "#         feature_vector = sess.run(embeddings, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/home/hoanviettran/Downloads/train/Aaron_Peirsol'\n",
    "files = [f for f in listdir(src_path) if isfile(join(src_path, f))]\n",
    "# for person_dir in person_dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/light/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "images = np.zeros((len(files), image_size, image_size, 3))\n",
    "for j, file_name in enumerate(files):\n",
    "    file_path = src_path + '/' + file_name\n",
    "    img = misc.imread(file_path)\n",
    "#     response, faces, bboxs = align_face(img, pnet, rnet, onet)\n",
    "    images[j,:,:,:] = facenet.load_img(img, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ff732d4868ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mimages_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# extracted_dict[person_dir] = feature_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/light/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/light/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "feed_dict = {images_placeholder:images, phase_train_placeholder:False}\n",
    "feature_vector = sess.run(embeddings, feed_dict=feed_dict)\n",
    "# extracted_dict[person_dir] = feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6ccd0db9122b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mretrieve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/data/Face_Recognition-vinayak/lib/src/retrieve.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                     help='Upper bound on the amount of GPU memory that will be used by the process.', default=1.0)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1738\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1739\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gpu_memory_fraction'], dest='gpu_memory_fraction', nargs=None, const=None, default=1.0, type=<class 'float'>, choices=None, help='Upper bound on the amount of GPU memory that will be used by the process.', metavar=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--lfw_batch_size', type=int,\n",
    "                    help='Number of images to process in a batch in the LFW test set.', default=100)\n",
    "parser.add_argument('--image_size', type=int,\n",
    "                    help='Image size (height, width) in pixels.', default=160)\n",
    "parser.add_argument('--detect_multiple_faces', type=bool,\n",
    "                    help='Detect and align multiple faces per image.', default=True)\n",
    "parser.add_argument('--margin', type=int,\n",
    "                    help='Margin for the crop around the bounding box (height, width) in pixels.', default=44)\n",
    "parser.add_argument('--random_order',\n",
    "                    help='Shuffles the order of images to enable alignment using multiple processes.', action='store_true')\n",
    "parser.add_argument('--gpu_memory_fraction', type=float,\n",
    "                    help='Upper bound on the amount of GPU memory that will be used by the process.', default=1.0)\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3a4e3dcca90f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'argv' is not defined"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--sum] N [N ...]\n",
      "ipykernel_launcher.py: error: argument N: invalid int value: '/run/user/1000/jupyter/kernel-7b2b275e-c292-4df5-8477-9b2897545fc5.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/light/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('integers', metavar='N', type=int, nargs='+',\n",
    "                    help='an integer for the accumulator')\n",
    "parser.add_argument('--sum', dest='accumulate', action='store_const',\n",
    "                    const=sum, default=max,\n",
    "                    help='sum the integers (default: find the max)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print (args.accumulate(args.integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/data/light/lib/python3.5/site-packages/ipykernel_launcher.py',\n",
       " '-f',\n",
       " '/run/user/1000/jupyter/kernel-7b2b275e-c292-4df5-8477-9b2897545fc5.json']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/mnt/data/Face_Recognition-vinayak/lib/src/extracted_dict.pickle','rb') as f:\n",
    "    feature_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(feature_array.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adrian_Nastase'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_array.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.append(a,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 5.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import retrieve\n",
    "from align import detect_face\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data/Face_Recognition-vinayak/lib/src/extracted_dict.pickle','rb') as f:\n",
    "    feature_array = pickle.load(f)\n",
    "model_exp = '/mnt/data/Face_Recognition-vinayak/lib/src/ckpt/20170512-110547/'\n",
    "graph_fr = tf.Graph()\n",
    "sess_fr = tf.Session(graph=graph_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/data/Face_Recognition-vinayak/lib/src/ckpt/20170512-110547/model-20170512-110547.ckpt-250000\n",
      "WARNING:tensorflow:Issue encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    }
   ],
   "source": [
    "with graph_fr.as_default():\n",
    "    saverf = tf.train.import_meta_graph(os.path.join(model_exp, 'model-20170512-110547.meta'))\n",
    "    saverf.restore(sess_fr, os.path.join(model_exp, 'model-20170512-110547.ckpt-250000'))\n",
    "    pnet, rnet, onet = detect_face.create_mtcnn(sess_fr, None)\n",
    "    writer = tf.summary.FileWriter(\"/mnt/data/Face_Recognition-vinayak/lib/src/\", sess_fr.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-10-cedb0e037f04>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-cedb0e037f04>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=\"/mnt/data/Face_Recognition-vinayak/lib/src/\"\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "from facenet import load_data, load_img, load_model, to_rgb\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import time\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "from align import detect_face\n",
    "from numba import jit, float32, njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(img, pnet, rnet, onet):\n",
    "\n",
    "    minsize = 20  # minimum size of face\n",
    "    threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "    factor = 0.709  # scale factor\n",
    "\n",
    "    # print(\"before img.size == 0\")\n",
    "    if img.size == 0:\n",
    "        print(\"empty array\")\n",
    "        return False, img, [0, 0, 0, 0]\n",
    "\n",
    "    if img.ndim < 2:\n",
    "        print('Unable to align')\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        img = to_rgb(img)\n",
    "\n",
    "    img = img[:, :, 0:3]\n",
    "\n",
    "    bounding_boxes, _ = detect_face.detect_face(\n",
    "        img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "    nrof_faces = bounding_boxes.shape[0]\n",
    "\n",
    "    if nrof_faces == 0:\n",
    "        return False, img, [0, 0, 0, 0]\n",
    "    else:\n",
    "        det = bounding_boxes[:, 0:4]\n",
    "        det_arr = []\n",
    "        img_size = np.asarray(img.shape)[0:2]\n",
    "        if nrof_faces > 1:\n",
    "            if detect_multiple_faces:\n",
    "                for i in range(nrof_faces):\n",
    "                    det_arr.append(np.squeeze(det[i]))\n",
    "            else:\n",
    "                bounding_box_size = (det[:, 2]-det[:, 0])*(det[:, 3]-det[:, 1])\n",
    "                img_center = img_size / 2\n",
    "                offsets = np.vstack(\n",
    "                    [(det[:, 0]+det[:, 2])/2-img_center[1], (det[:, 1]+det[:, 3])/2-img_center[0]])\n",
    "                offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n",
    "                # some extra weight on the centering\n",
    "                index = np.argmax(bounding_box_size-offset_dist_squared*2.0)\n",
    "                det_arr.append(det[index, :])\n",
    "        else:\n",
    "            det_arr.append(np.squeeze(det))\n",
    "        if len(det_arr) > 0:\n",
    "            faces = []\n",
    "            bboxes = []\n",
    "            for i, det in enumerate(det_arr):\n",
    "                det = np.squeeze(det)\n",
    "                bb = np.zeros(4, dtype=np.int32)\n",
    "                bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "                bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "                bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "                bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "                scaled = misc.imresize(\n",
    "                    cropped, (image_size,image_size), interp='bilinear')\n",
    "                # misc.imsave(\"cropped.png\", scaled)\n",
    "                faces.append(scaled)\n",
    "                bboxes.append(bb)\n",
    "                # print(\"leaving align face\")\n",
    "            return True, faces, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(['float32(float32[:,:],float32[:])'])\n",
    "# @jit()\n",
    "def compare_feature(vector, array):\n",
    "    return np.linalg.norm(array - vector)\n",
    "\n",
    "@jit()\n",
    "def identify_person(image_vector, feature_array, threshold):\n",
    "    distance_min = 2\n",
    "    result = ''\n",
    "    for j, person_features in enumerate(feature_array.values()):\n",
    "        num_features = person_features.shape[0]\n",
    "        for i in range (0,num_features):\n",
    "            distance_ps = compare_feature(image_vector, person_features[i,:])\n",
    "            if(distance_ps < distance_min):\n",
    "                distance_min = distance_ps\n",
    "                result = list(feature_array.keys())[j]\n",
    "    #     distance_ps = compare_feature(image_vector, person_features)\n",
    "    #     if(distance_ps < distance_min):\n",
    "    #         distance_min = distance_ps\n",
    "    #         person_id = j\n",
    "#     match = distance_min < threshold\n",
    "    # result = list(feature_array.keys())[person_id]\n",
    "    return distance_min, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_placeholder = sess_fr.graph.get_tensor_by_name(\"input:0\")\n",
    "images_placeholder = tf.image.resize_images(images_placeholder, (160, 160))\n",
    "embeddings = sess_fr.graph.get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = sess_fr.graph.get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "image_size = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/mnt/data/Face_dataset/lfw/'\n",
    "thresholds = np.arange(0.75, 1.0, 0.01)\n",
    "cases = len(thresholds)\n",
    "num_faces = 0\n",
    "num_registedface = 0\n",
    "true_detect = np.zeros(cases)\n",
    "false_detect = np.zeros(cases)\n",
    "person_dirs = [f for f in listdir(test_path) if isdir(join(test_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_path = test_path + person_dirs[0] + '/'\n",
    "files = [f for f in listdir(person_path) if isfile(join(person_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/light/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "file_path = person_path + files[0]\n",
    "img_cv = cv2.imread(file_path)\n",
    "frame = scipy.misc.imread(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/light/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "response, faces, bboxs = align_face(frame, pnet, rnet, onet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_multiple_faces = True\n",
    "image_size = 160\n",
    "margin = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_img(faces[0], image_size)\n",
    "start = time.time()\n",
    "feed_dict = {images_placeholder: images,\n",
    "             phase_train_placeholder: False}\n",
    "feature_vector = sess_fr.run(embeddings, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019814252853393555\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "match, result = identify_person(feature_vector, feature_array, 0.8)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(person_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "for j, person_features in enumerate(feature_array.values()):\n",
    "    print(person_features.dtype)\n",
    "    if(j == 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_vector - person_features[0,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "thresholds = np.arange(1.0, 0.75, -0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.99\n",
      "0.98\n",
      "0.97\n",
      "0.96\n",
      "0.95\n",
      "0.94\n",
      "0.9299999999999999\n",
      "0.9199999999999999\n",
      "0.9099999999999999\n",
      "0.8999999999999999\n",
      "0.8899999999999999\n",
      "0.8799999999999999\n",
      "0.8699999999999999\n",
      "0.8599999999999999\n",
      "0.8499999999999999\n",
      "0.8399999999999999\n",
      "0.8299999999999998\n",
      "0.8199999999999998\n",
      "0.8099999999999998\n",
      "0.7999999999999998\n",
      "0.7899999999999998\n",
      "0.7799999999999998\n",
      "0.7699999999999998\n",
      "0.7599999999999998\n"
     ]
    }
   ],
   "source": [
    "for j, threshold in enumerate(thresholds):\n",
    "    print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76, 0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n",
       "       0.87, 0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97,\n",
       "       0.98, 0.99, 1.  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/media/hoanviettran/Seagate Backup Plus Drive/FaceDataset/train_celebrity/celebrity/'\n",
    "files = [f for f in listdir(src_path) if isdir(join(src_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15653"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
