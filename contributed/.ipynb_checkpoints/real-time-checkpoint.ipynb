{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face\n",
    "import facenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /mnt/data/pretrained-models/20180402-114759\n",
      "Metagraph file: model-20180402-114759.meta\n",
      "Checkpoint file: model-20180402-114759.ckpt-275\n",
      "INFO:tensorflow:Restoring parameters from /mnt/data/pretrained-models/20180402-114759/model-20180402-114759.ckpt-275\n"
     ]
    }
   ],
   "source": [
    "# face_recognition = face.Recognition()\n",
    "encoder = face.Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/hoanviettran/Pictures/tranlap2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_test = face.Face()\n",
    "img_rgb = cv2.resize(img_rgb, (160, 160)) \n",
    "face_test.image = img_rgb\n",
    "embedding = encoder.generate_embedding(face_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, float32, guvectorize, void, vectorize, njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dict = open('Gino_dict_2018.pickle', 'rb')\n",
    "std_dict = pickle.load(std_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(embedding, std_dict):\n",
    "    distances = np.linalg.norm(embedding - std_dict['embeddings_array'], axis=1)\n",
    "    label_indx = np.argmin(distances)\n",
    "    match_class = std_dict['name_array'][std_dict['labels_array'][label_indx]]\n",
    "    distance = distances[label_indx]\n",
    "    return distance, match_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018184185028076172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "# @jit()\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = facenet.get_dataset('/mnt/data/Face_dataset/Gino')\n",
    "image_list, label_list, label_strings = facenet.get_image_paths_and_labels(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnhCuong',\n",
       " 'AnhDung',\n",
       " 'AnhHIeu',\n",
       " 'AnhQuy',\n",
       " 'AnhTien',\n",
       " 'AnhTinh',\n",
       " 'AnhToan',\n",
       " 'AnhTruong',\n",
       " 'BaoThanhThien',\n",
       " 'DinhTonThep',\n",
       " 'DuongManhCuong',\n",
       " 'NamDz',\n",
       " 'NgoThieuQuang',\n",
       " 'PhamVanTien',\n",
       " 'ThayMinh',\n",
       " 'Tien',\n",
       " 'TranVietHoan',\n",
       " 'anh Nghia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  113\n",
      "Number of batches:  2\n"
     ]
    }
   ],
   "source": [
    "nrof_images = len(image_list)\n",
    "print('Number of images: ', nrof_images)\n",
    "batch_size = 100\n",
    "nrof_batches = nrof_images / batch_size\n",
    "if nrof_batches > int(nrof_batches):\n",
    "    nrof_batches = int(nrof_batches) + 1\n",
    "print('Number of batches: ', nrof_batches)\n",
    "# embedding_size = embeddings.get_shape()[1]\n",
    "emb_array = np.zeros((nrof_images, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(nrof_batches):\n",
    "    if i == nrof_batches -1:\n",
    "        n = nrof_images\n",
    "    else:\n",
    "        n = i*batch_size + batch_size\n",
    "    # Get images for the batch\n",
    "    if args.is_aligned is True:\n",
    "        images = facenet.load_data(image_list[i*batch_size:n], False, False, args.image_size)\n",
    "    else:\n",
    "        images = load_and_align_data(image_list[i*batch_size:n], args.image_size, args.margin, args.gpu_memory_fraction)\n",
    "    feed_dict = { images_placeholder: images, phase_train_placeholder:False }\n",
    "    # Use the facenet model to calcualte embeddings\n",
    "    embed = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    emb_array[i*batch_size:n, :] = embed\n",
    "    print('Completed batch', i+1, 'of', nrof_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(8/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dict['embeddings_array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
